{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63dff1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# --- INPUTS (point to your BIG files) ---\n",
    "STATE = \"GA\"\n",
    "RATES_PARQ_BIG = Path(r\"C:\\Users\\ChristopherCato\\OneDrive - clarity-dx.com\\code\\bph\\mrf-etl\\data\\raw\\rates_uhc.parquet\")\n",
    "PROV_PARQ_BIG  = Path(r\"C:\\Users\\ChristopherCato\\OneDrive - clarity-dx.com\\code\\bph\\mrf-etl\\prod_etl\\data\\input\\prov_uhc.parquet\")\n",
    "\n",
    "# --- TEST SAMPLING ---\n",
    "TEST_MODE = True\n",
    "SAMPLE_ROWS_RATES = 100_000   # ↓ adjust down if still heavy (e.g., 20_000)\n",
    "SAMPLE_ROWS_PROV  = 50_000\n",
    "\n",
    "# Optional: restrict to a month or simple filter (speeds up a lot if column exists)\n",
    "# e.g., WHERE negotiated_rate IS NOT NULL\n",
    "RATES_WHERE = \"negotiated_rate IS NOT NULL\"\n",
    "PROV_WHERE  = \"\"  # often okay empty\n",
    "\n",
    "# Optional: restrict column set even more for the test\n",
    "RATES_COLS = [\n",
    "    \"last_updated_on\",\"reporting_entity_name\",\"version\",\n",
    "    \"billing_class\",\"billing_code_type\",\"billing_code\",\n",
    "    \"service_codes\",\"negotiated_type\",\"negotiation_arrangement\",\n",
    "    \"negotiated_rate\",\"expiration_date\",\"description\",\"name\",\n",
    "    \"provider_reference_id\",\"provider_group_id\",\"provider_group_id_raw\"\n",
    "]\n",
    "PROV_COLS = [\n",
    "    \"last_updated_on\",\"reporting_entity_name\",\"version\",\n",
    "    \"provider_group_id\",\"provider_reference_id\",\n",
    "    \"npi\",\"tin_type\",\"tin_value\"\n",
    "]\n",
    "\n",
    "# --- OUTPUTS (test sandbox) ---\n",
    "TEST_ROOT = Path(\"core/test_sandbox\")\n",
    "TEST_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "RATES_SAMPLE = TEST_ROOT / \"rates_sample.parquet\"\n",
    "PROV_SAMPLE  = TEST_ROOT / \"prov_sample.parquet\"\n",
    "\n",
    "# --- PIPELINE SPEED TOGGLES ---\n",
    "FAST_SKIP_POS = True      # True = skip parsing service_codes/pos_set (huge win)\n",
    "FAST_SKIP_XREFS = False   # True = skip building NPI/TIN xrefs (if providers file is huge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b8d260",
   "metadata": {},
   "source": [
    "cell 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c36b3b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote samples:\n",
      "   core\\test_sandbox\\rates_sample.parquet\n",
      "   core\\test_sandbox\\prov_sample.parquet\n"
     ]
    }
   ],
   "source": [
    "import duckdb, os\n",
    "from pathlib import Path\n",
    "\n",
    "if not RATES_PARQ_BIG.exists():\n",
    "    raise FileNotFoundError(RATES_PARQ_BIG)\n",
    "if not PROV_PARQ_BIG.exists():\n",
    "    raise FileNotFoundError(PROV_PARQ_BIG)\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "def list_columns_for_query(con, path: Path) -> list[str]:\n",
    "    # DESCRIBE the relation to get its column names\n",
    "    path_sql = str(path).replace(\"'\", \"''\")\n",
    "    cols_df = con.execute(f\"DESCRIBE SELECT * FROM read_parquet('{path_sql}')\").fetchdf()\n",
    "    # DuckDB returns 'column_name' in DESCRIBE output\n",
    "    return cols_df[\"column_name\"].tolist()\n",
    "\n",
    "def build_select_list(avail_cols: list[str], desired_cols: list[str]) -> str:\n",
    "    cols = [c for c in desired_cols if c in avail_cols]\n",
    "    if len(cols) == 0:\n",
    "        return \"*\"  # fallback if none of the desired columns exist\n",
    "    return \", \".join([f'\"{c}\"' for c in cols])\n",
    "\n",
    "def can_apply_where(avail_cols: list[str], where_expr: str) -> bool:\n",
    "    # very simple guard: only allow our default negotiated_rate filter if that column exists\n",
    "    if not where_expr.strip():\n",
    "        return True\n",
    "    # tune this if you add more complex WHEREs\n",
    "    needed = {\"negotiated_rate\"}\n",
    "    return needed.issubset(set(avail_cols))\n",
    "\n",
    "def copy_sample(in_path: Path, out_path: Path, desired_cols: list[str], where_expr: str, sample_rows: int):\n",
    "    path_sql = str(in_path).replace(\"'\", \"''\")\n",
    "    out_sql  = str(out_path).replace(\"'\", \"''\")\n",
    "\n",
    "    avail = list_columns_for_query(con, in_path)\n",
    "    sel = build_select_list(avail, desired_cols)\n",
    "    where_sql = f\"WHERE {where_expr}\" if (where_expr.strip() and can_apply_where(avail, where_expr)) else \"\"\n",
    "    sample_sql = f\"USING SAMPLE reservoir({sample_rows} rows)\"\n",
    "\n",
    "    con.execute(f\"\"\"\n",
    "      COPY (\n",
    "        SELECT {sel}\n",
    "        FROM read_parquet('{path_sql}')\n",
    "        {where_sql}\n",
    "        {sample_sql}\n",
    "      ) TO '{out_sql}' (FORMAT PARQUET, COMPRESSION ZSTD);\n",
    "    \"\"\")\n",
    "\n",
    "# ---- Build samples safely ----\n",
    "copy_sample(RATES_PARQ_BIG, RATES_SAMPLE, RATES_COLS, RATES_WHERE, SAMPLE_ROWS_RATES)\n",
    "copy_sample(PROV_PARQ_BIG,  PROV_SAMPLE,  PROV_COLS,  PROV_WHERE,  SAMPLE_ROWS_PROV)\n",
    "\n",
    "print(\"Wrote samples:\")\n",
    "print(\"  \", RATES_SAMPLE)\n",
    "print(\"  \", PROV_SAMPLE)\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efda14d",
   "metadata": {},
   "source": [
    "cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318f03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, hashlib, json\n",
    "import polars as pl\n",
    "import duckdb\n",
    "from datetime import datetime\n",
    "\n",
    "def md5(s: str) -> str:\n",
    "    return hashlib.md5(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    if s is None: return \"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"-\", s).strip(\"-\")\n",
    "    s = re.sub(r\"-+\", \"-\", s)\n",
    "    return s\n",
    "\n",
    "def _co(x): return \"\" if x is None else str(x)\n",
    "\n",
    "PAYER_SLUG_OVERRIDE = None\n",
    "def payer_slug_from_name(name: str) -> str:\n",
    "    return PAYER_SLUG_OVERRIDE or slugify(name or \"\")\n",
    "\n",
    "def normalize_yymm(date_str: str | None) -> str:\n",
    "    if not date_str: return \"\"\n",
    "    for fmt in (\"%Y-%m-%d\",\"%Y/%m/%d\",\"%Y-%m\",\"%Y/%m\",\"%Y%m%d\",\"%Y%m\"):\n",
    "        try:\n",
    "            dt = datetime.strptime(date_str[:len(re.sub(r'[^Ymd]', '', fmt))], fmt)\n",
    "            return dt.strftime(\"%Y-%m\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    m = re.search(r\"(20\\d{2})[-/](0[1-9]|1[0-2])\", date_str)\n",
    "    return f\"{m.group(1)}-{m.group(2)}\" if m else \"\"\n",
    "\n",
    "def normalize_service_codes(svc) -> list[str]:\n",
    "    if svc is None: return []\n",
    "    if isinstance(svc, (list, tuple)):\n",
    "        vals = [\"\" if v is None else str(v) for v in svc]\n",
    "    else:\n",
    "        s = str(svc)\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                parsed = json.loads(s)\n",
    "                vals = [\"\" if v is None else str(v) for v in parsed] if isinstance(parsed, list) else re.split(r\"[;,|\\s]+\", s)\n",
    "            except Exception:\n",
    "                vals = re.split(r\"[;,|\\s]+\", s)\n",
    "        else:\n",
    "            vals = re.split(r\"[;,|\\s]+\", s)\n",
    "    cleaned = [str(v).strip() for v in vals if str(v).strip()]\n",
    "    return sorted(set(cleaned))\n",
    "\n",
    "def pos_set_id_from_members(members) -> str:\n",
    "    if members is None:\n",
    "        return md5(\"none\")\n",
    "    try:\n",
    "        n = len(members)\n",
    "    except Exception:\n",
    "        members = [str(members)]\n",
    "        n = 1\n",
    "    if n == 0:\n",
    "        return md5(\"none\")\n",
    "    parts = [\"\" if m is None else str(m) for m in members]\n",
    "    return md5(\"|\".join(parts))\n",
    "\n",
    "def pg_uid_from_parts(payer_slug: str, version: str | None, pgid: str | None, pref: str | None) -> str:\n",
    "    key = f\"{_co(payer_slug)}|{_co(version)}|{_co(pgid)}|{_co(pref)}\"\n",
    "    return md5(key)\n",
    "\n",
    "def fact_uid_from_struct(s: dict) -> str:\n",
    "    try:\n",
    "        rate_str = f\"{float(s.get('negotiated_rate')):.4f}\" if s.get('negotiated_rate') is not None else \"\"\n",
    "    except Exception:\n",
    "        rate_str = \"\"\n",
    "    parts = [\n",
    "        _co(s.get(\"state\")),\n",
    "        _co(s.get(\"year_month\")),\n",
    "        _co(s.get(\"payer_slug\")),\n",
    "        _co(s.get(\"billing_class\")),\n",
    "        _co(s.get(\"code_type\")),\n",
    "        _co(s.get(\"code\")),\n",
    "        _co(s.get(\"pg_uid\")),\n",
    "        _co(s.get(\"pos_set_id\")),\n",
    "        _co(s.get(\"negotiated_type\")),\n",
    "        _co(s.get(\"negotiation_arrangement\")),\n",
    "        _co(s.get(\"expiration_date\")),\n",
    "        rate_str,\n",
    "        _co(s.get(\"provider_group_id_raw\")),\n",
    "    ]\n",
    "    return md5(\"|\".join(parts))\n",
    "\n",
    "def read_parquet_safely(path: Path, desired_cols: list[str]) -> pl.DataFrame:\n",
    "    lf = pl.scan_parquet(str(path))\n",
    "    avail = set(lf.columns)\n",
    "    use_cols = [c for c in desired_cols if c in avail]\n",
    "    df = lf.select(use_cols).collect()\n",
    "    missing = [c for c in desired_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        df = df.with_columns([pl.lit(None).alias(c) for c in missing])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc551a74",
   "metadata": {},
   "source": [
    "cell 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e3b144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChristopherCato\\AppData\\Local\\Temp\\ipykernel_34748\\1567895211.py:91: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  avail = set(lf.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rates_sample rows: 100000 cols: 16\n",
      "prov_sample  rows: 17855 cols: 8\n"
     ]
    }
   ],
   "source": [
    "rates = read_parquet_safely(RATES_SAMPLE, RATES_COLS)\n",
    "prov  = read_parquet_safely(PROV_SAMPLE,  PROV_COLS)\n",
    "print(\"rates_sample rows:\", rates.height, \"cols:\", len(rates.columns))\n",
    "print(\"prov_sample  rows:\", prov.height, \"cols:\", len(prov.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa9949",
   "metadata": {},
   "source": [
    "cell 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f476eb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base rows: 100000\n",
      "dim_code_new: 3678  dim_pg_new: 245  dim_pos_new: 1\n"
     ]
    }
   ],
   "source": [
    "# payer + year_month\n",
    "base = (\n",
    "    rates\n",
    "    .with_columns([\n",
    "        pl.col(\"reporting_entity_name\").fill_null(\"\").alias(\"ren\"),\n",
    "        pl.col(\"version\").fill_null(\"\").alias(\"ver\"),\n",
    "        pl.col(\"last_updated_on\").fill_null(\"\").alias(\"luo\"),\n",
    "    ])\n",
    "    .with_columns([\n",
    "        pl.col(\"ren\").map_elements(payer_slug_from_name, return_dtype=pl.Utf8).alias(\"payer_slug\"),\n",
    "        pl.col(\"luo\").map_elements(normalize_yymm, return_dtype=pl.Utf8).alias(\"year_month\"),\n",
    "    ])\n",
    ")\n",
    "\n",
    "# POS set (fast toggle)\n",
    "if FAST_SKIP_POS or \"service_codes\" not in base.columns:\n",
    "    base = base.with_columns([\n",
    "        pl.lit([]).alias(\"pos_members\"),\n",
    "        pl.lit(md5(\"none\")).alias(\"pos_set_id\"),\n",
    "    ])\n",
    "else:\n",
    "    base = (\n",
    "        base\n",
    "        .with_columns(\n",
    "            pl.col(\"service_codes\").map_elements(normalize_service_codes, return_dtype=pl.List(pl.Utf8)).alias(\"pos_members\")\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(\"pos_members\").map_elements(pos_set_id_from_members, return_dtype=pl.Utf8).alias(\"pos_set_id\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Provider group UID\n",
    "base = base.with_columns(\n",
    "    pl.struct([\"payer_slug\",\"version\",\"provider_group_id\",\"provider_reference_id\"])\n",
    "      .map_elements(lambda s: pg_uid_from_parts(s[\"payer_slug\"], s[\"version\"], s[\"provider_group_id\"], s[\"provider_reference_id\"]),\n",
    "                    return_dtype=pl.Utf8)\n",
    "      .alias(\"pg_uid\")\n",
    ")\n",
    "\n",
    "# ---- dims/xrefs candidates ----\n",
    "dim_code_new = (\n",
    "    base.select([\n",
    "        pl.col(\"billing_code_type\").alias(\"code_type\"),\n",
    "        pl.col(\"billing_code\").cast(pl.Utf8).alias(\"code\"),\n",
    "        pl.col(\"description\").alias(\"code_description\"),\n",
    "        pl.col(\"name\").alias(\"code_name\"),\n",
    "    ]).drop_nulls(subset=[\"code_type\",\"code\"]).unique()\n",
    ")\n",
    "\n",
    "dim_payer_new = (\n",
    "    base.select([\n",
    "        pl.col(\"payer_slug\"),\n",
    "        pl.col(\"reporting_entity_name\").alias(\"reporting_entity_name\"),\n",
    "        pl.col(\"version\").alias(\"version\"),\n",
    "    ]).drop_nulls(subset=[\"payer_slug\"]).unique()\n",
    ")\n",
    "\n",
    "dim_pg_new = (\n",
    "    base.select([\n",
    "        pl.col(\"pg_uid\"),\n",
    "        pl.col(\"payer_slug\"),\n",
    "        pl.coalesce([pl.col(\"provider_group_id\"), pl.col(\"provider_reference_id\")]).alias(\"provider_group_id_raw\"),\n",
    "        pl.col(\"version\"),\n",
    "    ]).drop_nulls(subset=[\"pg_uid\"]).unique()\n",
    ")\n",
    "\n",
    "dim_pos_new = base.select([\"pos_set_id\",\"pos_members\"]).drop_nulls(subset=[\"pos_set_id\"]).unique()\n",
    "\n",
    "# XREFs (optional skip if too heavy)\n",
    "if FAST_SKIP_XREFS:\n",
    "    xref_pg_npi_new = pl.DataFrame({\"pg_uid\": [], \"npi\": []})\n",
    "    xref_pg_tin_new = pl.DataFrame({\"pg_uid\": [], \"tin_type\": [], \"tin_value\": []})\n",
    "else:\n",
    "    prov_aug = (\n",
    "        prov\n",
    "          .with_columns([\n",
    "              pl.col(\"reporting_entity_name\").fill_null(\"\").alias(\"ren\"),\n",
    "              pl.col(\"version\").fill_null(\"\").alias(\"ver\"),\n",
    "          ])\n",
    "          .with_columns(pl.col(\"ren\").map_elements(payer_slug_from_name, return_dtype=pl.Utf8).alias(\"payer_slug\"))\n",
    "          .with_columns(\n",
    "              pl.struct([\"payer_slug\",\"version\",\"provider_group_id\",\"provider_reference_id\"])\n",
    "                .map_elements(lambda s: pg_uid_from_parts(s[\"payer_slug\"], s[\"version\"], s[\"provider_group_id\"], s[\"provider_reference_id\"]),\n",
    "                              return_dtype=pl.Utf8)\n",
    "                .alias(\"pg_uid\")\n",
    "          )\n",
    "    )\n",
    "    xref_pg_npi_new = prov_aug.select([\"pg_uid\",\"npi\"]).drop_nulls(subset=[\"pg_uid\",\"npi\"]).unique()\n",
    "    xref_pg_tin_new = prov_aug.select([\"pg_uid\",\"tin_type\",\"tin_value\"]).drop_nulls(subset=[\"pg_uid\",\"tin_value\"]).unique()\n",
    "\n",
    "print(\"base rows:\", base.height)\n",
    "print(\"dim_code_new:\", dim_code_new.height, \" dim_pg_new:\", dim_pg_new.height, \" dim_pos_new:\", dim_pos_new.height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc4dcf",
   "metadata": {},
   "source": [
    "cell 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20071605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dims/xrefs written.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "TEST_DIM_DIR  = TEST_ROOT / \"dims\"\n",
    "TEST_XREF_DIR = TEST_ROOT / \"xrefs\"\n",
    "TEST_GOLD_DIR = TEST_ROOT / \"gold\"\n",
    "for p in (TEST_DIM_DIR, TEST_XREF_DIR, TEST_GOLD_DIR):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DIM_CODE_FILE = TEST_DIM_DIR / \"dim_code.parquet\"\n",
    "DIM_PAYER_FILE = TEST_DIM_DIR / \"dim_payer.parquet\"\n",
    "DIM_PG_FILE = TEST_DIM_DIR / \"dim_provider_group.parquet\"\n",
    "DIM_POS_FILE = TEST_DIM_DIR / \"dim_pos_set.parquet\"\n",
    "XREF_PG_NPI = TEST_XREF_DIR / \"xref_pg_member_npi.parquet\"\n",
    "XREF_PG_TIN = TEST_XREF_DIR / \"xref_pg_member_tin.parquet\"\n",
    "GOLD_FACT_FILE = TEST_GOLD_DIR / \"fact_rate.parquet\"\n",
    "\n",
    "def append_unique_parquet(df_new: pl.DataFrame, path: Path, keys: list[str]):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if path.exists():\n",
    "        old_keys = pl.read_parquet(path, columns=keys).unique()\n",
    "        to_add = df_new.join(old_keys, on=keys, how=\"anti\")\n",
    "    else:\n",
    "        to_add = df_new\n",
    "    if to_add.is_empty():\n",
    "        return\n",
    "    tmp_new = path.with_suffix(\".new.parquet\")\n",
    "    tmp_out = path.with_suffix(\".next.parquet\")\n",
    "    to_add.write_parquet(tmp_new, compression=\"zstd\")\n",
    "    con = duckdb.connect()\n",
    "    if path.exists():\n",
    "        con.execute(f\"\"\"\n",
    "          COPY (\n",
    "            SELECT * FROM read_parquet('{path}')\n",
    "            UNION ALL\n",
    "            SELECT * FROM read_parquet('{tmp_new}')\n",
    "          ) TO '{tmp_out}' (FORMAT PARQUET, COMPRESSION ZSTD);\n",
    "        \"\"\")\n",
    "    else:\n",
    "        con.execute(f\"\"\"\n",
    "          COPY (SELECT * FROM read_parquet('{tmp_new}'))\n",
    "          TO '{tmp_out}' (FORMAT PARQUET, COMPRESSION ZSTD);\n",
    "        \"\"\")\n",
    "    con.close()\n",
    "    os.replace(tmp_out, path)\n",
    "    os.remove(tmp_new)\n",
    "\n",
    "append_unique_parquet(dim_code_new, DIM_CODE_FILE, keys=[\"code_type\",\"code\"])\n",
    "append_unique_parquet(dim_payer_new, DIM_PAYER_FILE, keys=[\"payer_slug\"])\n",
    "append_unique_parquet(dim_pg_new,   DIM_PG_FILE,    keys=[\"pg_uid\"])\n",
    "append_unique_parquet(dim_pos_new,  DIM_POS_FILE,   keys=[\"pos_set_id\"])\n",
    "append_unique_parquet(xref_pg_npi_new, XREF_PG_NPI, keys=[\"pg_uid\",\"npi\"])\n",
    "append_unique_parquet(xref_pg_tin_new, XREF_PG_TIN, keys=[\"pg_uid\",\"tin_value\"])\n",
    "\n",
    "print(\"Test dims/xrefs written.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c75f9a",
   "metadata": {},
   "source": [
    "cell 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4429cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact_new rows: 78514\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>fact_uid</th><th>state</th><th>year_month</th><th>payer_slug</th><th>billing_class</th><th>code_type</th><th>code</th><th>pg_uid</th><th>pos_set_id</th><th>negotiated_type</th><th>negotiation_arrangement</th><th>negotiated_rate</th><th>expiration_date</th><th>provider_group_id_raw</th><th>reporting_entity_name</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;6386f61dc8bbd95b8451e41f76a055…</td><td>&quot;GA&quot;</td><td>&quot;2025-08&quot;</td><td>&quot;unitedhealthcare-of-georgia-in…</td><td>&quot;professional&quot;</td><td>&quot;CPT&quot;</td><td>&quot;19101&quot;</td><td>&quot;a4384c5b4444d255c1d13fac116781…</td><td>&quot;334c4a4c42fdb79d7ebc3e73b517e6…</td><td>&quot;negotiated&quot;</td><td>&quot;ffs&quot;</td><td>356.14</td><td>&quot;9999-12-31&quot;</td><td>491</td><td>&quot;UnitedHealthcare of Georgia In…</td></tr><tr><td>&quot;5e4f1c32d4513965485c46b82bdc35…</td><td>&quot;GA&quot;</td><td>&quot;2025-08&quot;</td><td>&quot;unitedhealthcare-of-georgia-in…</td><td>&quot;professional&quot;</td><td>&quot;CPT&quot;</td><td>&quot;75891&quot;</td><td>&quot;6fafb8326ef12759167a3d744e8b00…</td><td>&quot;334c4a4c42fdb79d7ebc3e73b517e6…</td><td>&quot;negotiated&quot;</td><td>&quot;ffs&quot;</td><td>390.42</td><td>&quot;9999-12-31&quot;</td><td>177</td><td>&quot;UnitedHealthcare of Georgia In…</td></tr><tr><td>&quot;674af5f5954f8d5775b0349b290588…</td><td>&quot;GA&quot;</td><td>&quot;2025-08&quot;</td><td>&quot;unitedhealthcare-of-georgia-in…</td><td>&quot;institutional&quot;</td><td>&quot;CPT&quot;</td><td>&quot;26706&quot;</td><td>&quot;d860297eb9da59e1cadd7e847271f1…</td><td>&quot;334c4a4c42fdb79d7ebc3e73b517e6…</td><td>&quot;negotiated&quot;</td><td>&quot;ffs&quot;</td><td>997.0</td><td>&quot;9999-12-31&quot;</td><td>290</td><td>&quot;UnitedHealthcare of Georgia In…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 15)\n",
       "┌────────────┬───────┬────────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ fact_uid   ┆ state ┆ year_month ┆ payer_slug ┆ … ┆ negotiate ┆ expiratio ┆ provider_ ┆ reporting │\n",
       "│ ---        ┆ ---   ┆ ---        ┆ ---        ┆   ┆ d_rate    ┆ n_date    ┆ group_id_ ┆ _entity_n │\n",
       "│ str        ┆ str   ┆ str        ┆ str        ┆   ┆ ---       ┆ ---       ┆ raw       ┆ ame       │\n",
       "│            ┆       ┆            ┆            ┆   ┆ f64       ┆ str       ┆ ---       ┆ ---       │\n",
       "│            ┆       ┆            ┆            ┆   ┆           ┆           ┆ i64       ┆ str       │\n",
       "╞════════════╪═══════╪════════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 6386f61dc8 ┆ GA    ┆ 2025-08    ┆ unitedheal ┆ … ┆ 356.14    ┆ 9999-12-3 ┆ 491       ┆ UnitedHea │\n",
       "│ bbd95b8451 ┆       ┆            ┆ thcare-of- ┆   ┆           ┆ 1         ┆           ┆ lthcare   │\n",
       "│ e41f76a055 ┆       ┆            ┆ georgia-in ┆   ┆           ┆           ┆           ┆ of        │\n",
       "│ …          ┆       ┆            ┆ …          ┆   ┆           ┆           ┆           ┆ Georgia   │\n",
       "│            ┆       ┆            ┆            ┆   ┆           ┆           ┆           ┆ In…       │\n",
       "│ 5e4f1c32d4 ┆ GA    ┆ 2025-08    ┆ unitedheal ┆ … ┆ 390.42    ┆ 9999-12-3 ┆ 177       ┆ UnitedHea │\n",
       "│ 513965485c ┆       ┆            ┆ thcare-of- ┆   ┆           ┆ 1         ┆           ┆ lthcare   │\n",
       "│ 46b82bdc35 ┆       ┆            ┆ georgia-in ┆   ┆           ┆           ┆           ┆ of        │\n",
       "│ …          ┆       ┆            ┆ …          ┆   ┆           ┆           ┆           ┆ Georgia   │\n",
       "│            ┆       ┆            ┆            ┆   ┆           ┆           ┆           ┆ In…       │\n",
       "│ 674af5f595 ┆ GA    ┆ 2025-08    ┆ unitedheal ┆ … ┆ 997.0     ┆ 9999-12-3 ┆ 290       ┆ UnitedHea │\n",
       "│ 4f8d5775b0 ┆       ┆            ┆ thcare-of- ┆   ┆           ┆ 1         ┆           ┆ lthcare   │\n",
       "│ 349b290588 ┆       ┆            ┆ georgia-in ┆   ┆           ┆           ┆           ┆ of        │\n",
       "│ …          ┆       ┆            ┆ …          ┆   ┆           ┆           ┆           ┆ Georgia   │\n",
       "│            ┆       ┆            ┆            ┆   ┆           ┆           ┆           ┆ In…       │\n",
       "└────────────┴───────┴────────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build fact_new with 'state' in key\n",
    "fact_new = (\n",
    "    base\n",
    "      .with_columns(pl.lit(STATE).alias(\"state\"))\n",
    "      .select(\n",
    "          \"state\",\n",
    "          pl.col(\"year_month\"),\n",
    "          pl.col(\"payer_slug\"),\n",
    "          pl.col(\"billing_class\"),\n",
    "          pl.col(\"billing_code_type\").alias(\"code_type\"),\n",
    "          pl.col(\"billing_code\").cast(pl.Utf8).alias(\"code\"),\n",
    "          pl.col(\"pg_uid\"),\n",
    "          pl.col(\"pos_set_id\"),\n",
    "          pl.col(\"negotiated_type\"),\n",
    "          pl.col(\"negotiation_arrangement\"),\n",
    "          pl.col(\"negotiated_rate\").cast(pl.Float64).alias(\"negotiated_rate\"),\n",
    "          pl.col(\"expiration_date\"),\n",
    "          pl.coalesce([pl.col(\"provider_group_id\"), pl.col(\"provider_reference_id\")]).alias(\"provider_group_id_raw\"),\n",
    "          pl.col(\"reporting_entity_name\"),\n",
    "      )\n",
    "      .with_columns(\n",
    "          pl.struct([\n",
    "              \"state\",\"year_month\",\"payer_slug\",\"billing_class\",\"code_type\",\"code\",\n",
    "              \"pg_uid\",\"pos_set_id\",\"negotiated_type\",\"negotiation_arrangement\",\n",
    "              \"expiration_date\",\"negotiated_rate\",\"provider_group_id_raw\"\n",
    "          ]).map_elements(fact_uid_from_struct, return_dtype=pl.Utf8).alias(\"fact_uid\")\n",
    "      )\n",
    "      .select(\n",
    "          \"fact_uid\",\"state\",\"year_month\",\"payer_slug\",\"billing_class\",\"code_type\",\"code\",\n",
    "          \"pg_uid\",\"pos_set_id\",\"negotiated_type\",\"negotiation_arrangement\",\n",
    "          \"negotiated_rate\",\"expiration_date\",\"provider_group_id_raw\",\"reporting_entity_name\"\n",
    "      )\n",
    "      .unique()\n",
    ")\n",
    "\n",
    "print(\"fact_new rows:\", fact_new.height)\n",
    "fact_new.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02c6e08",
   "metadata": {},
   "source": [
    "cell 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e57f5bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created core\\test_sandbox\\gold\\fact_rate.parquet with 78514 rows.\n"
     ]
    }
   ],
   "source": [
    "def upsert_fact_single(fact_batch: pl.DataFrame, out_file: Path):\n",
    "    if fact_batch.is_empty():\n",
    "        print(\"No fact rows in batch.\")\n",
    "        return\n",
    "    need_cols = {\n",
    "        \"fact_uid\",\"state\",\"year_month\",\"payer_slug\",\"billing_class\",\"code_type\",\"code\",\n",
    "        \"pg_uid\",\"pos_set_id\",\"negotiated_type\",\"negotiation_arrangement\",\n",
    "        \"negotiated_rate\",\"expiration_date\",\"provider_group_id_raw\",\"reporting_entity_name\"\n",
    "    }\n",
    "    missing = need_cols - set(fact_batch.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"fact_batch missing columns: {sorted(missing)}\")\n",
    "    out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_new = str(out_file.with_suffix(\".stage.parquet\"))\n",
    "    tmp_out = str(out_file.with_suffix(\".next.parquet\"))\n",
    "    fact_batch.select(sorted(list(need_cols))).write_parquet(tmp_new, compression=\"zstd\")\n",
    "    con = duckdb.connect()\n",
    "    if not out_file.exists():\n",
    "        con.execute(f\"\"\"\n",
    "          COPY (SELECT * FROM read_parquet('{tmp_new}'))\n",
    "          TO '{out_file}' (FORMAT PARQUET, COMPRESSION ZSTD);\n",
    "        \"\"\")\n",
    "        con.close()\n",
    "        os.remove(tmp_new)\n",
    "        print(f\"Created {out_file} with {fact_batch.height} rows.\")\n",
    "        return\n",
    "    con.execute(f\"\"\"\n",
    "      CREATE OR REPLACE TABLE _all   AS SELECT * FROM read_parquet('{out_file}');\n",
    "      CREATE OR REPLACE TABLE _stage AS SELECT * FROM read_parquet('{tmp_new}');\n",
    "      INSERT INTO _all\n",
    "      SELECT s.* FROM _stage s\n",
    "      LEFT JOIN _all a ON a.fact_uid = s.fact_uid\n",
    "      WHERE a.fact_uid IS NULL;\n",
    "      COPY (SELECT * FROM _all) TO '{tmp_out}' (FORMAT PARQUET, COMPRESSION ZSTD);\n",
    "    \"\"\")\n",
    "    con.close()\n",
    "    os.replace(tmp_out, out_file)\n",
    "    os.remove(tmp_new)\n",
    "    print(f\"Upsert complete into {out_file}.\")\n",
    "\n",
    "upsert_fact_single(fact_new, GOLD_FACT_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c54d1c4",
   "metadata": {},
   "source": [
    "cell 9 sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc4e6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row counts (test sandbox):\n",
      "  dim_code         : 3678\n",
      "  dim_payer        : 1\n",
      "  dim_provider_grp : 245\n",
      "  dim_pos_set      : 1\n",
      "  xref_pg_npi      : 16999\n",
      "  xref_pg_tin      : 9486\n",
      "  fact_rate (gold) : 78514\n"
     ]
    }
   ],
   "source": [
    "def count_parquet_rows(path: Path) -> int:\n",
    "    if not path.exists(): return 0\n",
    "    con = duckdb.connect()\n",
    "    n = con.execute(f\"SELECT COUNT(*) FROM read_parquet('{str(path)}')\").fetchone()[0]\n",
    "    con.close()\n",
    "    return int(n)\n",
    "\n",
    "print(\"Row counts (test sandbox):\")\n",
    "print(\"  dim_code         :\", count_parquet_rows(DIM_CODE_FILE))\n",
    "print(\"  dim_payer        :\", count_parquet_rows(DIM_PAYER_FILE))\n",
    "print(\"  dim_provider_grp :\", count_parquet_rows(DIM_PG_FILE))\n",
    "print(\"  dim_pos_set      :\", count_parquet_rows(DIM_POS_FILE))\n",
    "print(\"  xref_pg_npi      :\", count_parquet_rows(XREF_PG_NPI))\n",
    "print(\"  xref_pg_tin      :\", count_parquet_rows(XREF_PG_TIN))\n",
    "print(\"  fact_rate (gold) :\", count_parquet_rows(GOLD_FACT_FILE))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
